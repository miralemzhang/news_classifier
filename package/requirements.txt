# Core inference
transformers>=4.57.0,<5.0.0
torch>=2.0.0,<3.0.0
qwen-vl-utils>=0.0.14,<1.0.0

# API server
fastapi>=0.100.0,<1.0.0
uvicorn>=0.20.0,<1.0.0
pydantic>=2.0.0,<3.0.0

# Data processing
numpy>=1.24.0,<3.0.0

# Image processing (required by qwen-vl-utils)
Pillow>=9.0.0,<12.0.0
